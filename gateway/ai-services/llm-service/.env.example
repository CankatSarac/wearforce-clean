# LLM Service Environment Configuration

# Service Configuration
SERVICE_NAME=llm-service
HOST=0.0.0.0
PORT=8004
DEBUG=false
ENVIRONMENT=production

# Deployment Type
DEPLOYMENT_TYPE=edge  # Options: "cloud" or "edge"

# Model Paths
GPT_OSS_20B_PATH=/app/models/gpt-oss-20b
GPT_OSS_120B_PATH=/app/models/gpt-oss-120b

# vLLM Configuration
TENSOR_PARALLEL_SIZE=1
MAX_NUM_SEQS=128
MAX_MODEL_LEN=4096
SWAP_SPACE=4
LLM_GPU_MEMORY=0.75

# Batch Processing
BATCH_SIZE=32
BATCH_TIMEOUT=0.1

# Redis Configuration
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_DB=0
REDIS_MAX_CONNECTIONS=20

# Database Configuration
DB_HOST=postgres
DB_PORT=5432
DB_USER=postgres
DB_PASSWORD=postgres
DB_NAME=wearforce

# Monitoring and Metrics
METRICS_ENABLED=true
METRICS_PORT=8000
LOG_LEVEL=INFO
LOG_STRUCTURED=true

# CORS Settings
CORS_ORIGINS=["*"]
CORS_ALLOW_CREDENTIALS=true

# Rate Limiting
RATE_LIMIT_PER_MINUTE=60

# Health Checks
HEALTH_CHECK_INTERVAL=30

# CUDA Configuration
CUDA_VISIBLE_DEVICES=0
NVIDIA_VISIBLE_DEVICES=all

# Performance Tuning
OMP_NUM_THREADS=1
MKL_NUM_THREADS=1
MAX_JOBS=4